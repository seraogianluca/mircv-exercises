{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Exercise6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seraogianluca/mircv-exercises/blob/main/Exercise6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EiBxo72GLxg"
      },
      "source": [
        "#MIRCV 2021\n",
        "# Gianluca Serao\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS9XDzxsTDz1"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "from IPython.display import display\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "BASE_DIR = '/content/gdrive/My Drive/mircv2021/data/learning'\n",
        "TRAIN_DATA_DIR = os.path.join(BASE_DIR, 'CNRPark')\n",
        "TEST_DATA_DIR = os.path.join(BASE_DIR, 'CNRParkTest')\n",
        "\n",
        "with open(os.path.join(BASE_DIR, \"imagenet-classes.txt\")) as f:\n",
        "  CLASS_NAMES = f.read().splitlines()\n",
        "\n",
        "# convert classnames 'free','busy' in numeric 0,1,...\n",
        "MAPPING = {label: num for num, label in enumerate( ('free','busy') )} # create the mapping {'free': 0, 'busy': 1}\n",
        "TEST_IMAGE = os.path.join(BASE_DIR, 'cat.jpg')\n",
        "\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuP3y4blAMOf"
      },
      "source": [
        "# Classification using a pretrained model\r\n",
        "\r\n",
        "we will use *MobileNetV2* -- a compact network pretrained on ImageNet (ILSVRC-2012) -- to classify an image.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmP8sQix5ALk"
      },
      "source": [
        "model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=True\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtb1sODzFFAe"
      },
      "source": [
        "print(model.input.shape)\n",
        "print(model.output.shape)\n",
        "\n",
        "input_size = model.input.shape[1:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow0dARWVKuxR"
      },
      "source": [
        "The pretrained MobileNetV2 accepts 224x224 float32 images with pixel values in the range \\[-1, 1\\].\r\n",
        "Once we loaded the image into a uint8 numpy array, the line\r\n",
        "\r\n",
        "> x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\r\n",
        "\r\n",
        "converts it in float32 in the pixel range \\[-1, 1\\], that is equivalent to:\r\n",
        "\r\n",
        "> x = (x / 127.5) - 1\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0725kXDF_A6w"
      },
      "source": [
        "pil_image = load_img(TEST_IMAGE, target_size=input_size)\n",
        "display(pil_image)\n",
        "\n",
        "np_image = np.array(pil_image)  # uint8, [0, 255]\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(np_image)  # float32, [-1, 1]\n",
        "x = np.expand_dims(x, axis=0)  # add batch dimension\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_rAP1728wEt"
      },
      "source": [
        "# classification with Tensorflow\n",
        "predictions = model.predict(x)[0]  # there is only 1 image in the batch\n",
        "\n",
        "# print the top 5 predictions\n",
        "top5 = np.argsort(predictions)[::-1][:5]\n",
        "top5_probabilities = predictions[top5]\n",
        "for index, probability in zip(top5, top5_probabilities):\n",
        "  print('{:.2f} {} (#{})'.format(probability, CLASS_NAMES[index], index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jasuCay9AHzA"
      },
      "source": [
        "# Transfer Learning on the CNRPark dataset\r\n",
        "\r\n",
        "You will experiment with three ways to perform transfer learning from a pretrained network for the classification of a new dataset:\r\n",
        "\r\n",
        "\r\n",
        "*   **A**  --  you will fix the bottom layers of a pretrained network and learn a new Multi-layer Perceptron (MLP) classifier on top of them.\r\n",
        "\r\n",
        "*   **B**  -- you will extract features from the same fixed bottom layers and train a Support Vector Machine (SVM) classifier on them.\r\n",
        "\r\n",
        "*   **C**  -- you will finetune all the layers of a pretrained network to learn to classify the new dataset.\r\n",
        "\r\n",
        "The goal of this exercise is to implement, finetune, evaluate, and compare these methodologies.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSUOVKjkA0xH"
      },
      "source": [
        "## Data Loading (using tf.data API)\r\n",
        "\r\n",
        "We use *image_dataset_from_directory()* provided by Keras to load the image dataset. The function returns a *tf.data.Dataset* object -- an abstraction that provides a way to iterate over data that might not fit entirely in main memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXZbQjg4A8KI"
      },
      "source": [
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    TRAIN_DATA_DIR,\n",
        "    subset=\"training\",\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    TRAIN_DATA_DIR,\n",
        "    subset=\"validation\",\n",
        "    shuffle=False,\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    TEST_DATA_DIR,\n",
        "    shuffle=False,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# we define also a train data loader that does not shuffle data (useful for features extraction)\n",
        "train_dataset_noshuf = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    TRAIN_DATA_DIR,\n",
        "    subset=\"training\",\n",
        "    shuffle=False,\n",
        "    validation_split=0.2,\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGXpEafvRjVL"
      },
      "source": [
        "Let's inspect what kind of data is returned by the streaming dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_j3WAspBqMP"
      },
      "source": [
        "# get the first batch from the streaming dataset\n",
        "batch = next(iter(train_dataset))  \n",
        "images, labels = batch\n",
        "print(images.shape, labels.shape)\n",
        "\n",
        "# inspect data type\n",
        "images = images.numpy()\n",
        "print(images.dtype, images.min(), images.max())  # float32, [0, 255]\n",
        "\n",
        "# show some images\n",
        "sample_images = np.hstack(images[:5])  # stack 5 images horizontally\n",
        "sample_images = sample_images.astype(np.uint8)  # PIL wants uint8\n",
        "sample_images = PIL.Image.fromarray(sample_images)  # to PIL image\n",
        "display(sample_images)  # show it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EzHL3vrRxML"
      },
      "source": [
        "We use *.map()* to apply a preprocessing step to all the images in the dataset to match the desired format for MobileNetV2.\r\n",
        "\r\n",
        "This will be executed lazily when we request a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5509LzehBxP2"
      },
      "source": [
        "def preprocess(images, labels):\n",
        "  # rescales from [0, 255] to [-1, 1], equivalent to:  images = (images / 127.5) - 1\n",
        "  images = tf.keras.applications.mobilenet_v2.preprocess_input(images)\n",
        "  return images, labels\n",
        "\n",
        "# apply prepocessing to datasets (lazy operation)\n",
        "train_dataset = train_dataset.map(preprocess, deterministic=True)\n",
        "valid_dataset = valid_dataset.map(preprocess, deterministic=True)\n",
        "test_dataset = test_dataset.map(preprocess, deterministic=True)\n",
        "\n",
        "train_dataset_noshuf = train_dataset_noshuf.map(preprocess, deterministic=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRM3a-ovJKhF"
      },
      "source": [
        "# utility function that iterates a streaming dataset and collect all the labels (useful for sklearn functions)\n",
        "def get_all_labels(dataset):\n",
        "    labels_only = [labels.numpy() for _, labels in dataset]  # get labels only\n",
        "    labels_only = np.concatenate(labels_only)  # concatenate all batches in a unique array\n",
        "    return labels_only"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAvB02cVBkhP"
      },
      "source": [
        "## **Model A** -- Fixed pretrained layers + new fully-connected classifier on top"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhBSPm-EQFW"
      },
      "source": [
        "# TODO\n",
        "# Build the model using MobileNetV2\n",
        "pretrained_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False  # do not include the pretrained layers implementing the imagenet classifier\n",
        ")\n",
        "\n",
        "# freezes weights of all levels of the pre-trained network\n",
        "pretrained_model.trainable = False \n",
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = pretrained_model(inputs, training=False)\n",
        "# Add a global average pooling\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='gap')(x)\n",
        "# Add a FC level (Dense) of 256 neurons\n",
        "x = tf.keras.layers.Dense(256, activation='relu', name='classifier_hidden')(x)\n",
        "# Add binary output classification level\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# create an optimizer (RMSprop or Adam) and select a reasonable learning rate\n",
        "# use the sparse_categorical_crossentropy loss\n",
        "# use accuracy as evaluation metric\n",
        "# configure the network with the chosen optimizer, loss, and metrics\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuiJHtr28wFB"
      },
      "source": [
        "# TODO\n",
        "# Train the model for a reasonable number of epochs\n",
        "model.fit(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    epochs=20, \n",
        "    validation_data=valid_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDiv_C4jWqhE"
      },
      "source": [
        "# evaluate the model on the test set with evaluate() ...\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBwLjcYH2c5x"
      },
      "source": [
        "# ... or use predict() and sklearn to evaluate the model\n",
        "test_predictions = model.predict(test_dataset)  # probabilities for all classes\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)  # index of the classes with largest probability\n",
        "\n",
        "test_labels = get_all_labels(test_dataset)\n",
        "\n",
        "m = confusion_matrix(test_labels, test_predictions)\n",
        "print(m)\n",
        "print( (m[0,0] + m[1,1]) / len(test_labels) ) \n",
        "print( accuracy_score(test_labels, test_predictions) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPQlE4s6Go2c"
      },
      "source": [
        "## **Model B** -- SVM on extracted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk8Xh7JUylcn"
      },
      "source": [
        "# TODO\n",
        "# build the feature extractor model from MobileNetV2\n",
        "# same as model A add just a global average pooling\n",
        "model_b = tf.keras.Sequential()\n",
        "model_b.add(pretrained_model)\n",
        "model_b.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model_b.summary()\n",
        "\n",
        "# extract the feature from train, validation, and test\n",
        "train_features = model_b.predict(train_dataset_noshuf, batch_size=BATCH_SIZE)\n",
        "valid_features = model_b.predict(valid_dataset, batch_size=BATCH_SIZE)\n",
        "test_features = model_b.predict(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# and normalize them\n",
        "train_features = sklearn.preprocessing.normalize(train_features)\n",
        "valid_features = sklearn.preprocessing.normalize(valid_features)\n",
        "test_features = sklearn.preprocessing.normalize(test_features)\n",
        "\n",
        "# for train use the train_dataset_noshuf (to avoid shuffling)\n",
        "# get also label vectors for training and evaluation with sklearn\n",
        "train_labels = get_all_labels(train_dataset_noshuf)\n",
        "valid_labels = get_all_labels(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vtp-r3OzK-O"
      },
      "source": [
        "# TODO\n",
        "# train SVMs: the C hyperparameter regularize the model (controls overfit)\n",
        "# test various values of C in geometric progression and try to get the best accuracy on the validation set\n",
        "C = []\n",
        "scores = []\n",
        "r = 0.5\n",
        "a = 1.0\n",
        "\n",
        "C = [a * (0.5 ** i) for i in range(5)]\n",
        "\n",
        "for c in C:\n",
        "  svm_classifier = sklearn.svm.LinearSVC(C=c)\n",
        "  svm_classifier.fit(train_features, train_labels)\n",
        "  scores.append(svm_classifier.score(valid_features,valid_labels))\n",
        "\n",
        "result = zip(scores, C)\n",
        "result = sorted(result, reverse=True)\n",
        "print(\"C: \", C)\n",
        "print(\"Sorted by score: \", result)\n",
        "\n",
        "C_best = result[0][0]\n",
        "svm_classifier = sklearn.svm.LinearSVC(C=C_best)\n",
        "svm_classifier.fit(train_features, train_labels)\n",
        "print(\"Validation accuracy: \", svm_classifier.score(valid_features,valid_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoJzAf_A0CHX"
      },
      "source": [
        "# evaluate the classifier on the test set\n",
        "test_predictions = svm_classifier.predict(test_features)\n",
        "m = confusion_matrix(test_labels, test_predictions)\n",
        "print(m)\n",
        "print(accuracy_score(test_labels, test_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JImCdyLf3E4t"
      },
      "source": [
        "## **Model C** -- Finetune all layers of a pretrained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdxlINmA2D4J"
      },
      "source": [
        "# TODO\n",
        "# Build the model with the MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False\n",
        ")\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "model_finetune = tf.keras.Sequential()\n",
        "model_finetune.add(base_model)\n",
        "# Add a global average pooling\n",
        "model_finetune.add(tf.keras.layers.GlobalAveragePooling2D(name='gap'))\n",
        "# Add a binary output classification level\n",
        "model_finetune.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model_finetune.summary()\n",
        "\n",
        "# create an optimizer (RMSprop or Adam) and select a reasonable learning rate\n",
        "# use the sparse_categorical_crossentropy loss\n",
        "# use accuracy as evaluation metric\n",
        "# configure the network with the chosen optimizer, loss, and metrics\n",
        "# train the network, tune the hyperparameters looking at the accuracy on the validation set\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\n",
        "model_finetune.compile(optimizer=optimizer, \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_finetune.fit(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    epochs=10, \n",
        "    validation_data=valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdg5aIlBMCU8"
      },
      "source": [
        "# evaluate it on the test set\n",
        "test_predictions = model_finetune.predict(test_dataset)  # probabilities for all classes\n",
        "test_predictions = np.argmax(test_predictions, axis=-1)  # index of the class with largest probability\n",
        "\n",
        "test_labels = get_all_labels(test_dataset)\n",
        "\n",
        "print( confusion_matrix(test_labels, test_predictions) )\n",
        "print( accuracy_score(test_labels, test_predictions) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qfNyYxHTGbT"
      },
      "source": [
        "# **Retrieval Test**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljrUQ4K-TjzE"
      },
      "source": [
        "n_queries = 5\r\n",
        "k = 91\r\n",
        "\r\n",
        "test_images, test_labels = zip(*test_dataset)\r\n",
        "test_images = np.concatenate(test_images)\r\n",
        "test_labels = np.concatenate(test_labels)\r\n",
        "# np.concatenate([images for images, _ in test_dataset])  # get only the images\r\n",
        "\r\n",
        "# query_indexes = [78, 80, 89, 23, 20]\r\n",
        "# query_indexes = [14, 78, 79, 12, 18]\r\n",
        "query_indexes = [14, 78,  2, 18,  9]\r\n",
        "# query_indexes = np.random.choice(len(test_images), n_queries, replace=False)  # get 10 queries at random\r\n",
        "query_images = test_images[query_indexes]\r\n",
        "query_labels = test_labels[query_indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm_TeLRjTmrT"
      },
      "source": [
        "# utility function to extract and normalize features\r\n",
        "def extract_features(feature_extractor, images):\r\n",
        "  features = feature_extractor.predict(images, batch_size=BATCH_SIZE)\r\n",
        "  features = sklearn.preprocessing.normalize(features)\r\n",
        "  return features\r\n",
        "\r\n",
        "# utility function to perform kNN search\r\n",
        "def search(query_features, db_features, k):\r\n",
        "  scores = np.dot(query_features, db_features.T)  # compute cosine scores\r\n",
        "  ranks = np.argsort(-scores, axis=1)  # order for descending score (NOTE the minus sign)\r\n",
        "\r\n",
        "  topk = ranks[:, :k]  # get the top-k indices for each query\r\n",
        "  n_queries = len(query_features)\r\n",
        "  topk_scores = scores[np.arange(n_queries).reshape(-1, 1), topk]  # get the top-k scores for each query\r\n",
        "  return topk, topk_scores\r\n",
        "\r\n",
        "# utility to resize, pad, and write score on images\r\n",
        "preview_size = 80\r\n",
        "def process_images(image, score, is_relevant):\r\n",
        "  # to uint8 [0, 255]\r\n",
        "  image = ((image + 1) * 127.5).astype(np.uint8)\r\n",
        "\r\n",
        "  # add a red/green flag\r\n",
        "  color = (0, 255, 0) if is_relevant else (255, 0, 0)\r\n",
        "  flag = np.full((10, 224, 3), fill_value=color, dtype=image.dtype)\r\n",
        "  image = np.concatenate((image, flag), axis=0)\r\n",
        "\r\n",
        "  # resize\r\n",
        "  image = Image.fromarray(image).convert('RGBA')\r\n",
        "  image.thumbnail((preview_size, preview_size))  # use PIL to resize the image\r\n",
        "\r\n",
        "  # draw score\r\n",
        "  draw = ImageDraw.Draw(image)\r\n",
        "  draw.text((3, preview_size - 12), f'{score:.2f}', anchor='lt', fill=(255, 255, 255, 255))\r\n",
        "\r\n",
        "  # pad the image with transparency\r\n",
        "  image = ImageOps.expand(image, 5, fill=(0, 0, 0, 0))\r\n",
        "  image = np.array(image)\r\n",
        "  return image\r\n",
        "\r\n",
        "# use np.vectorize to apply custom functions to numpy arrays\r\n",
        "np_process_image = np.vectorize(process_images, signature='(h,w,c),(),()->(h1,w1,c1)')\r\n",
        "\r\n",
        "# utility function to draw knn results for multiple queries\r\n",
        "def show_results(images, scores, is_relevant):\r\n",
        "  # images has shape (n_queries, k, H, W, C)\r\n",
        "  images = np_process_image(images, scores, is_relevant)\r\n",
        "  images = np.concatenate(images, axis=1)  # concatenate queries vertically\r\n",
        "  images = np.concatenate(images, axis=1)  # concatenate results horizontally\r\n",
        "  display(Image.fromarray(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b87caR0TsyT"
      },
      "source": [
        "def evaluate_knn_search(model, query_images, query_labels, db_images, db_labels, k):\r\n",
        "  query_features = extract_features(model, query_images)\r\n",
        "  db_features = extract_features(model, db_images)\r\n",
        "\r\n",
        "  query_labels = query_labels.reshape(-1, 1)  # reshape to use numpy broadcasting\r\n",
        "\r\n",
        "  topk, topk_scores = search(query_features, db_features, k)\r\n",
        "  # topk_images = db_images[topk]\r\n",
        "  topk_labels = db_labels[topk]\r\n",
        "  topk_is_relevant = topk_labels == query_labels\r\n",
        "\r\n",
        "  aps = [sklearn.metrics.average_precision_score(l, s) for l,s in zip(topk_is_relevant, topk_scores)]\r\n",
        "  print('APs per Query:', aps)\r\n",
        "  print('mAP:', np.mean(aps))\r\n",
        "\r\n",
        "  # show_results(topk_images, topk_scores, topk_is_relevant)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1oyIKWTv5n"
      },
      "source": [
        "pretrained_feature_extractor = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, pooling='avg')\r\n",
        "new_classifier_feature_extractor = Model(inputs=model.input, outputs=model.get_layer('classifier_hidden').output)\r\n",
        "finetuned_feature_extractor = Model(inputs=model_finetune.input, outputs=model_finetune.get_layer('gap').output)\r\n",
        "\r\n",
        "print('\\nModel pretrained on ImageNet (GAP)')\r\n",
        "evaluate_knn_search(pretrained_feature_extractor, query_images, query_labels, test_images, test_labels, k)\r\n",
        "\r\n",
        "print('\\nModel frozen with top trained on CNRPark (Classifier Hidden 256D)')\r\n",
        "evaluate_knn_search(new_classifier_feature_extractor, query_images, query_labels, test_images, test_labels, k)\r\n",
        "\r\n",
        "print('\\nModel finetuned on CNRPark (GAP)')\r\n",
        "evaluate_knn_search(finetuned_feature_extractor, query_images, query_labels, test_images, test_labels, k)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}